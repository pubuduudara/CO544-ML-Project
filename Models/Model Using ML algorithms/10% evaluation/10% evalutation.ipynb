{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frequency(frame,featrue):\n",
    "    dfr=pd.DataFrame()\n",
    "    Frequency=frame[featrue].value_counts() \n",
    "    total_count=len(frame)\n",
    "    percentage=Frequency/total_count * 100\n",
    "    percentage=percentage.round(2)\n",
    "    dfr['Frequency']=frame[featrue].value_counts() \n",
    "    dfr['%']=percentage\n",
    "    return dfr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('data.csv')\n",
    "#df_train=df_train.sample(frac=1)\n",
    "df_test=pd.read_excel('testdata_10%.xlsx')\n",
    "frames=[df_train,df_test]\n",
    "#df=pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmark='?'\n",
    "df_train.replace(qmark,np.NaN,inplace=True)\n",
    "df_test.replace(qmark,np.NaN,inplace=True)\n",
    "#df_train=df_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(DataFrame_Name):\n",
    "    \n",
    "    sum_null = DataFrame_Name.isnull().sum()\n",
    "    total_count = DataFrame_Name.isnull().count()\n",
    "    percent_nullvalues = sum_null/total_count * 100\n",
    "    df_null = pd.DataFrame()\n",
    "    df_null['Total_values'] = total_count\n",
    "    df_null['Null_Count'] = sum_null\n",
    "    df_null['Percent'] = percent_nullvalues\n",
    "    df_null = df_null.sort_values(by='Null_Count',ascending = False)\n",
    "\n",
    "    return(df_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Checking for NULL values ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null_values(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null_values(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Checking column data types before filling null values ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['A2']=df_train['A2'].astype(str).astype(float)\n",
    "df_test['A2']=df_test['A2'].astype(str).astype(float)\n",
    "\n",
    "df_train['A14']=df_train['A14'].astype(str).astype(float)\n",
    "df_test['A14']=df_test['A14'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------- filling Null values ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2_mean=df_train['A2'].mean()\n",
    "A14_mean=df_train['A14'].mean()\n",
    "\n",
    "A1_max_occurrence=df_train['A1'].value_counts().index[0]\n",
    "A6_max_occurrence=df_train['A6'].value_counts().index[0]\n",
    "A9_max_occurrence=df_train['A9'].value_counts().index[0]\n",
    "A3_max_occurrence=df_train['A3'].value_counts().index[0]\n",
    "A4_max_occurrence=df_train['A4'].value_counts().index[0]\n",
    "\n",
    "df_train=df_train.fillna({'A2':A2_mean,'A14':A14_mean,'A1':A1_max_occurrence,'A6':A6_max_occurrence,'A9':A9_max_occurrence,'A3':A3_max_occurrence,'A4':A4_max_occurrence})\n",
    "df_test=df_test.fillna({'A1':A1_max_occurrence})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------- preprocess 1 --------------------------------------------------------------------------\n",
    "\n",
    "# print(show_frequency(df_test,'A3'))\n",
    "#    Frequency      %\n",
    "# u         11  78.57\n",
    "# y          3  21.43\n",
    "\n",
    "# print(show_frequency(df_train,'A3'))\n",
    "#    Frequency      %\n",
    "# u        420  76.09\n",
    "# y        130  23.55\n",
    "# l          2   0.36\n",
    "\n",
    "# since there are only 2 entries as l in 'A3' of the training set, replace them with U\n",
    "df_train['A3'] = df_train['A3'].replace('l','u')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------- preprocess 2 --------------------------------------------------------------------------\n",
    "\n",
    "# print(show_frequency(df_test,'A4'))\n",
    "#    Frequency      %\n",
    "# g         11  78.57\n",
    "# p          3  21.43\n",
    "\n",
    "# print(show_frequency(df_train,'A4'))\n",
    "#     Frequency      %\n",
    "# g         420  76.09\n",
    "# p         130  23.55\n",
    "# gg          2   0.36\n",
    "\n",
    "\n",
    "# since there are only 2 entries as l in 'A4' of the training set, replace them with U\n",
    "df_train['A4'] = df_train['A3'].replace('gg','g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Encode caragorical data -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encodings (Without True/False) can be done to ------> A1,A3,A4\n",
    "\n",
    "# encode A16 lables success =1 failure =0\n",
    "df_train['A16'] = df_train['A16'].map({label:idx for idx,label in enumerate(np.unique(df_train['A16']))})\n",
    "\n",
    "# encode A1 lables a =0 b =1 \n",
    "df_train['A1'] = df_train['A1'].map({label:idx for idx,label in enumerate(np.unique(df_train['A1']))})\n",
    "df_test['A1'] = df_test['A1'].map({label:idx for idx,label in enumerate(np.unique(df_test['A1']))})\n",
    "\n",
    "# encode A8 lables false =0 true =1\n",
    "df_train['A8'] = df_train['A8'].map({label:idx for idx,label in enumerate(np.unique(df_train['A8']))})\n",
    "df_test['A8'] = df_test['A8'].map({label:idx for idx,label in enumerate(np.unique(df_test['A8']))})\n",
    "\n",
    "# encode A11 lables false =0 true =1\n",
    "df_train['A11'] = df_train['A11'].map({label:idx for idx,label in enumerate(np.unique(df_train['A11']))})\n",
    "df_test['A11'] = df_test['A11'].map({label:idx for idx,label in enumerate(np.unique(df_test['A11']))})\n",
    "\n",
    "# encode A13 lables false =0 true =1\n",
    "df_train['A13'] = df_train['A13'].map({label:idx for idx,label in enumerate(np.unique(df_train['A13']))})\n",
    "df_test['A13'] = df_test['A13'].map({label:idx for idx,label in enumerate(np.unique(df_test['A13']))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_A3=df_train['A3'].map({label:idx for idx,label in enumerate(np.unique(df_train['A3']))})\n",
    "x_A4=df_train['A4'].map({label:idx for idx,label in enumerate(np.unique(df_train['A4']))})\n",
    "x_A6=pd.get_dummies(df_train[['A6']])\n",
    "x_A9=pd.get_dummies(df_train[['A9']])\n",
    "x_A15=pd.get_dummies(df_train[['A15']])\n",
    "\n",
    "df_train=pd.concat([df_train['A1'],df_train['A2'],x_A3,x_A4,df_train['A5'],x_A6,df_train['A7'],df_train['A8'],x_A9,df_train['A10'],df_train['A11'],df_train['A12'],df_train['A13'],df_train['A14'],x_A15,df_train['A16']],axis=1)\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_train.columns: \n",
    "#     print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_A3=df_test['A3'].map({label:idx for idx,label in enumerate(np.unique(df_test['A3']))})\n",
    "x_A4=df_test['A4'].map({label:idx for idx,label in enumerate(np.unique(df_test['A4']))})\n",
    "x_A6=pd.get_dummies(df_test[['A6']])\n",
    "x_A9=pd.get_dummies(df_test[['A9']])\n",
    "x_A15=pd.get_dummies(df_test[['A15']])\n",
    "\n",
    "df_test=pd.concat([df_test['A1'],df_test['A2'],x_A3,x_A4,df_test['A5'],x_A6,df_test['A7'],df_test['A8'],x_A9,df_test['A10'],df_test['A11'],df_test['A12'],df_test['A13'],df_test['A14'],x_A15],axis=1)\n",
    "\n",
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_train.columns: \n",
    "#     print(col,end=' ,') \n",
    "# print('-------------------')\n",
    "# for col in df_test.columns: \n",
    "#     print(col,end=' ,') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_columns(df_train,df_test):\n",
    "    col_train=list(df_train)\n",
    "    col_test=list(df_test)\n",
    "    size=len(col_train)\n",
    "   \n",
    "    for i in range(size):\n",
    "        col=col_train[i]\n",
    "        if col not in col_test:\n",
    "            df_test.insert(i,col,0)\n",
    "    \n",
    "            \n",
    "fill_missing_columns(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_train.columns: \n",
    "#     print(col,end=' ,') \n",
    "# print('-------------------')\n",
    "# for col in df_test.columns: \n",
    "#     print(col,end=' ,') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop(['A16'], axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=df_train.columns\n",
    "feature_cols=feature_cols[0:len(feature_cols)-1]\n",
    "\n",
    "#split dataset in features and target variable\n",
    "X = df_train[feature_cols] # Features\n",
    "y = df_train.A16 # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# X_train = df_train[feature_cols] # Features\n",
    "# y_train = df_train.A16 # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Feature scaling-------------------\n",
    "#-------------- Feature scaling --------------------------------------------\n",
    "# random forest, decision trees do not need feature scaling\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train = stdsc.fit_transform(X_train)\n",
    "X_test = stdsc.transform(X_test)\n",
    "df_test=stdsc.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------apply different modles -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8072289156626506\n",
      "Precision=  0.7875\n",
      "Recall=  0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = dt.predict(X_test)\n",
    "dt_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "dt_tree_precision=metrics.precision_score(y_test, y_pred)\n",
    "dt_tree_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.6807228915662651\n",
      "Precision=  0.7777777777777778\n",
      "Recall=  0.44871794871794873\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)\n",
    "gnb_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "gnb_precision=metrics.precision_score(y_test, y_pred)\n",
    "gnb_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8012048192771084\n",
      "Precision=  0.8082191780821918\n",
      "Recall=  0.7564102564102564\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "knn_precision=metrics.precision_score(y_test, y_pred)\n",
    "knn_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8554216867469879\n",
      "Precision=  0.8375\n",
      "Recall=  0.8589743589743589\n"
     ]
    }
   ],
   "source": [
    "svm = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = svm.predict(X_test)\n",
    "svm_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "svm_precision=metrics.precision_score(y_test, y_pred)\n",
    "svm_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8734939759036144\n",
      "Precision=  0.8518518518518519\n",
      "Recall=  0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = lr.predict(X_test)\n",
    "lr_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "lr_precision=metrics.precision_score(y_test, y_pred)\n",
    "lr_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.9036144578313253\n",
      "Precision=  0.9305555555555556\n",
      "Recall=  0.8589743589743589\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "rf_precision=metrics.precision_score(y_test, y_pred)\n",
    "rf_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------reuslts------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "output=rf.predict(df_test)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
