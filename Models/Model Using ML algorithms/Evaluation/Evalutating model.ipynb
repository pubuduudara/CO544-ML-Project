{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "#from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frequency(frame,featrue):\n",
    "    dfr=pd.DataFrame()\n",
    "    Frequency=frame[featrue].value_counts() \n",
    "    total_count=len(frame)\n",
    "    percentage=Frequency/total_count * 100\n",
    "    percentage=percentage.round(2)\n",
    "    dfr['Frequency']=frame[featrue].value_counts() \n",
    "    dfr['%']=percentage\n",
    "    return dfr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('fullset.csv')\n",
    "#df_train=df_train.sample(frac=1)\n",
    "df_test=pd.read_csv('testdata.csv')\n",
    "submission=df_test\n",
    "frames=[df_train,df_test]\n",
    "#df=pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmark='?'\n",
    "df_train.replace(qmark,np.NaN,inplace=True)\n",
    "df_test.replace(qmark,np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(DataFrame_Name):\n",
    "    \n",
    "    sum_null = DataFrame_Name.isnull().sum()\n",
    "    total_count = DataFrame_Name.isnull().count()\n",
    "    percent_nullvalues = sum_null/total_count * 100\n",
    "    df_null = pd.DataFrame()\n",
    "    df_null['Total_values'] = total_count\n",
    "    df_null['Null_Count'] = sum_null\n",
    "    df_null['Percent'] = percent_nullvalues\n",
    "    df_null = df_null.sort_values(by='Null_Count',ascending = False)\n",
    "\n",
    "    return(df_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Checking for NULL values ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null_values(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null_values(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Checking column data types before filling null values ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train['A2']=df_train['A2'].astype(str).astype(float)\n",
    "df_test['A2']=df_test['A2'].astype(str).astype(float)\n",
    "\n",
    "\n",
    "df_train['A14']=df_train['A14'].astype(str).astype(float)\n",
    "df_test['A14']=df_test['A14'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------- filling Null values ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2_mean=df_train['A2'].mean()\n",
    "A14_mean=df_train['A14'].mean()\n",
    "\n",
    "A1_max_occurrence=df_train['A1'].value_counts().index[0]\n",
    "A6_max_occurrence=df_train['A6'].value_counts().index[0]\n",
    "A9_max_occurrence=df_train['A9'].value_counts().index[0]\n",
    "A3_max_occurrence=df_train['A3'].value_counts().index[0]\n",
    "A4_max_occurrence=df_train['A4'].value_counts().index[0]\n",
    "\n",
    "df_train=df_train.fillna({'A2':A2_mean,'A14':A14_mean,'A1':A1_max_occurrence,'A6':A6_max_occurrence,'A9':A9_max_occurrence,'A3':A3_max_occurrence,'A4':A4_max_occurrence})\n",
    "df_test=df_test.fillna({'A1':A1_max_occurrence,'A6':A6_max_occurrence,'A9':A9_max_occurrence,'A14':A14_mean,'A2':A2_mean,'A3':A3_max_occurrence,'A4':A4_max_occurrence})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frequency      %\n",
      "u        525  76.09\n",
      "y        163  23.62\n",
      "l          2   0.29\n"
     ]
    }
   ],
   "source": [
    "#------------------------- preprocess 1 --------------------------------------------------------------------------\n",
    "\n",
    "# print(show_frequency(df_train,'A3'))\n",
    "#    Frequency      %\n",
    "# u         11  78.57\n",
    "# y          3  21.43\n",
    "\n",
    "print(show_frequency(df_train,'A3'))\n",
    "#    Frequency      %\n",
    "# u        420  76.09\n",
    "# y        130  23.55\n",
    "# l          2   0.36\n",
    "\n",
    "# since there are only 2 entries as l in 'A3' of the training set, replace them with U\n",
    "\n",
    "df_train['A3'] = df_train['A3'].replace('l','u')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------- preprocess 2 --------------------------------------------------------------------------\n",
    "\n",
    "# print(show_frequency(df_test,'A4'))\n",
    "#    Frequency      %\n",
    "# g         11  78.57\n",
    "# p          3  21.43\n",
    "\n",
    "# print(show_frequency(df_train,'A4'))\n",
    "#     Frequency      %\n",
    "# g         420  76.09\n",
    "# p         130  23.55\n",
    "# gg          2   0.36\n",
    "\n",
    "\n",
    "# since there are only 2 entries as l in 'A4' of the training set, replace them with U\n",
    "df_train['A4'] = df_train['A3'].replace('gg','g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------- preprocess 3 --------------------------------------------------------------------------\n",
    "# since A3,A4 are duplicated drop A4\n",
    "df_train=df_train.drop(['A4'], axis=1)\n",
    "df_test=df_test.drop(['A4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Encode caragorical data -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encodings (Without True/False) can be done to ------> A1,A3\n",
    "\n",
    "# encode A16 lables success =1 failure =0\n",
    "df_train['A16'] = df_train['A16'].map({label:idx for idx,label in enumerate(np.unique(df_train['A16']))})\n",
    "\n",
    "# encode A1 lables a =0 b =1 \n",
    "df_train['A1'] = df_train['A1'].map({label:idx for idx,label in enumerate(np.unique(df_train['A1']))})\n",
    "df_test['A1'] = df_test['A1'].map({label:idx for idx,label in enumerate(np.unique(df_test['A1']))})\n",
    "\n",
    "# encode A8 lables false =0 true =1\n",
    "df_train['A8'] = df_train['A8'].map({label:idx for idx,label in enumerate(np.unique(df_train['A8']))})\n",
    "df_test['A8'] = df_test['A8'].map({label:idx for idx,label in enumerate(np.unique(df_test['A8']))})\n",
    "\n",
    "# encode A11 lables false =0 true =1\n",
    "df_train['A11'] = df_train['A11'].map({label:idx for idx,label in enumerate(np.unique(df_train['A11']))})\n",
    "df_test['A11'] = df_test['A11'].map({label:idx for idx,label in enumerate(np.unique(df_test['A11']))})\n",
    "\n",
    "# encode A13 lables false =0 true =1\n",
    "df_train['A13'] = df_train['A13'].map({label:idx for idx,label in enumerate(np.unique(df_train['A13']))})\n",
    "df_test['A13'] = df_test['A13'].map({label:idx for idx,label in enumerate(np.unique(df_test['A13']))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6_aa</th>\n",
       "      <th>A6_c</th>\n",
       "      <th>A6_cc</th>\n",
       "      <th>A6_d</th>\n",
       "      <th>A6_e</th>\n",
       "      <th>A6_ff</th>\n",
       "      <th>...</th>\n",
       "      <th>A9_z</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15_g</th>\n",
       "      <th>A15_p</th>\n",
       "      <th>A15_s</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1.540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>0</td>\n",
       "      <td>5.625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2  A3     A5  A6_aa  A6_c  A6_cc  A6_d  A6_e  A6_ff  ...  A9_z  \\\n",
       "0   1  30.83   0  0.000      0     0      0     0     0      0  ...     0   \n",
       "1   0  58.67   0  4.460      0     0      0     0     0      0  ...     0   \n",
       "2   0  24.50   0  0.500      0     0      0     0     0      0  ...     0   \n",
       "3   1  27.83   0  1.540      0     0      0     0     0      0  ...     0   \n",
       "4   1  20.17   0  5.625      0     0      0     0     0      0  ...     0   \n",
       "\n",
       "    A10  A11  A12  A13    A14  A15_g  A15_p  A15_s  A16  \n",
       "0  1.25    1    1    0  202.0      1      0      0    1  \n",
       "1  3.04    1    6    0   43.0      1      0      0    1  \n",
       "2  1.50    1    0    0  280.0      1      0      0    1  \n",
       "3  3.75    1    5    1  100.0      1      0      0    1  \n",
       "4  1.71    1    0    0  120.0      0      0      1    1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#x_A4=df_train['A4'].map({label:idx for idx,label in enumerate(np.unique(df_train['A4']))})\n",
    "#x_A1=pd.get_dummies(df_train[['A1']])\n",
    "x_A3=df_train['A3'].map({label:idx for idx,label in enumerate(np.unique(df_train['A3']))})\n",
    "#x_A3=pd.get_dummies(df_train[['A3']])\n",
    "x_A6=pd.get_dummies(df_train[['A6']])\n",
    "x_A9=pd.get_dummies(df_train[['A9']])\n",
    "x_A15=pd.get_dummies(df_train[['A15']])\n",
    "\n",
    "df_train=pd.concat([df_train['A1'],df_train['A2'],x_A3,df_train['A5'],x_A6,df_train['A7'],df_train['A8'],x_A9,df_train['A10'],df_train['A11'],df_train['A12'],df_train['A13'],df_train['A14'],x_A15,df_train['A16']],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.67</td>\n",
       "      <td>y</td>\n",
       "      <td>9.00</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>h</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28.08</td>\n",
       "      <td>y</td>\n",
       "      <td>15.00</td>\n",
       "      <td>e</td>\n",
       "      <td>13212</td>\n",
       "      <td>0</td>\n",
       "      <td>z</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>73.42</td>\n",
       "      <td>u</td>\n",
       "      <td>17.75</td>\n",
       "      <td>ff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>64.08</td>\n",
       "      <td>u</td>\n",
       "      <td>20.00</td>\n",
       "      <td>x</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>51.58</td>\n",
       "      <td>u</td>\n",
       "      <td>15.00</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>v</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2 A3     A5  A6     A7  A8  A9    A10  A11  A12  A13    A14 A15\n",
       "0   1  32.67  y   9.00   w      0   0   h   5.25    1    0    1  154.0   g\n",
       "1   0  28.08  y  15.00   e  13212   0   z   0.00    1    0    0    0.0   g\n",
       "2   1  73.42  u  17.75  ff      0   0  ff   0.00    1    0    1    0.0   g\n",
       "3   1  64.08  u  20.00   x   1000   1   h  17.50    1    9    1    0.0   g\n",
       "4   1  51.58  u  15.00   c      0   1   v   8.50    1    9    0    0.0   g"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6_aa</th>\n",
       "      <th>A6_c</th>\n",
       "      <th>A6_cc</th>\n",
       "      <th>A6_d</th>\n",
       "      <th>A6_e</th>\n",
       "      <th>A6_ff</th>\n",
       "      <th>...</th>\n",
       "      <th>A9_v</th>\n",
       "      <th>A9_z</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15_g</th>\n",
       "      <th>A15_p</th>\n",
       "      <th>A15_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.67</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28.08</td>\n",
       "      <td>1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>64.08</td>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>51.58</td>\n",
       "      <td>0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2  A3     A5  A6_aa  A6_c  A6_cc  A6_d  A6_e  A6_ff  ...  A9_v  \\\n",
       "0   1  32.67   1   9.00      0     0      0     0     0      0  ...     0   \n",
       "1   0  28.08   1  15.00      0     0      0     0     1      0  ...     0   \n",
       "2   1  73.42   0  17.75      0     0      0     0     0      1  ...     0   \n",
       "3   1  64.08   0  20.00      0     0      0     0     0      0  ...     0   \n",
       "4   1  51.58   0  15.00      0     1      0     0     0      0  ...     1   \n",
       "\n",
       "   A9_z    A10  A11  A12  A13    A14  A15_g  A15_p  A15_s  \n",
       "0     0   5.25    1    0    1  154.0      1      0      0  \n",
       "1     1   0.00    1    0    0    0.0      1      0      0  \n",
       "2     0   0.00    1    0    1    0.0      1      0      0  \n",
       "3     0  17.50    1    9    1    0.0      1      0      0  \n",
       "4     0   8.50    1    9    0    0.0      1      0      0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_A1=pd.get_dummies(df_test[['A1']])\n",
    "#x_A3=pd.get_dummies(df_test[['A3']])\n",
    "x_A3=df_test['A3'].map({label:idx for idx,label in enumerate(np.unique(df_test['A3']))})\n",
    "#x_A4=df_test['A4'].map({label:idx for idx,label in enumerate(np.unique(df_test['A4']))})\n",
    "x_A6=pd.get_dummies(df_test[['A6']])\n",
    "x_A9=pd.get_dummies(df_test[['A9']])\n",
    "x_A15=pd.get_dummies(df_test[['A15']])\n",
    "\n",
    "df_test=pd.concat([df_test['A1'],df_test['A2'],x_A3,df_test['A5'],x_A6,df_test['A7'],df_test['A8'],x_A9,df_test['A10'],df_test['A11'],df_test['A12'],df_test['A13'],df_test['A14'],x_A15],axis=1)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_train.columns: \n",
    "#     print(col,end=' ,') \n",
    "# print('-------------------')\n",
    "# for col in df_test.columns: \n",
    "#     print(col,end=' ,') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_columns(df_train,df_test):\n",
    "    col_train=list(df_train)\n",
    "    col_test=list(df_test)\n",
    "    size=len(col_train)\n",
    "   \n",
    "    for i in range(size):\n",
    "        col=col_train[i]\n",
    "        if col not in col_test:\n",
    "            df_test.insert(i,col,0)\n",
    "    \n",
    "            \n",
    "fill_missing_columns(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_train.columns: \n",
    "#     print(col,end=' ,') \n",
    "# print('-------------------')\n",
    "# for col in df_test.columns: \n",
    "#     print(col,end=' ,') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop(['A16'], axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=df_train.columns\n",
    "feature_cols=feature_cols[0:len(feature_cols)-1]\n",
    "\n",
    "#split dataset in features and target variable\n",
    "X = df_train[feature_cols] # Features\n",
    "y = df_train.A16 # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# X_train = df_train[feature_cols] # Features\n",
    "# y_train = df_train.A16 # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Feature scaling-------------------\n",
    "\n",
    "\n",
    "# stdsc = StandardScaler()\n",
    "# X_train = stdsc.fit_transform(X_train)\n",
    "# X_test = stdsc.transform(X_test)\n",
    "# df_test=stdsc.transform(df_test)\n",
    "\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "stdsc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = stdsc.fit_transform(X_train)\n",
    "X_test = stdsc.fit_transform(X_test)\n",
    "df_test=stdsc.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------apply different modles -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8647342995169082\n",
      "Precision=  0.7878787878787878\n",
      "Recall=  0.9176470588235294\n",
      "CorssValid: 0.80 (+/- 0.17)\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = dt.predict(X_test)\n",
    "dt_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "dt_tree_precision=metrics.precision_score(y_test, y_pred)\n",
    "dt_tree_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(dt, X, y, cv=5)\n",
    "print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.748792270531401\n",
      "Precision=  0.8113207547169812\n",
      "Recall=  0.5058823529411764\n",
      "CorssValid: 0.81 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)\n",
    "gnb_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "gnb_precision=metrics.precision_score(y_test, y_pred)\n",
    "gnb_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(gnb, X, y, cv=5)\n",
    "print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8502415458937198\n",
      "Precision=  0.7934782608695652\n",
      "Recall=  0.8588235294117647\n",
      "CorssValid: 0.64 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "knn_precision=metrics.precision_score(y_test, y_pred)\n",
    "knn_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(knn, X, y, cv=5)\n",
    "print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8599033816425121\n",
      "Precision=  0.7692307692307693\n",
      "Recall=  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "svm = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = svm.predict(X_test)\n",
    "svm_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "svm_precision=metrics.precision_score(y_test, y_pred)\n",
    "svm_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# scores = cross_val_score(svm, X, y, cv=5)\n",
    "# print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8695652173913043\n",
      "Precision=  0.8452380952380952\n",
      "Recall=  0.8352941176470589\n"
     ]
    }
   ],
   "source": [
    "svm_l = LinearSVC() # Linear Kernel\n",
    "svm_l.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = svm_l.predict(X_test)\n",
    "svm_laccuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "svm_lprecision=metrics.precision_score(y_test, y_pred)\n",
    "svm_lrecall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# scores = cross_val_score(svm_l, X, y, cv=5)\n",
    "# print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8840579710144928\n",
      "Precision=  0.8210526315789474\n",
      "Recall=  0.9176470588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pubudu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Pubudu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Pubudu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Pubudu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorssValid: 0.85 (+/- 0.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pubudu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = lr.predict(X_test)\n",
    "lr_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "lr_precision=metrics.precision_score(y_test, y_pred)\n",
    "lr_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(lr, X, y, cv=5)\n",
    "print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8888888888888888\n",
      "Precision=  0.8369565217391305\n",
      "Recall=  0.9058823529411765\n",
      "CorssValid: 0.86 (+/- 0.21)\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "rf_precision=metrics.precision_score(y_test, y_pred)\n",
    "rf_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(rf, X, y, cv=5)\n",
    "print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=  0.8502415458937198\n",
      "Precision=  0.8\n",
      "Recall=  0.8470588235294118\n",
      "CorssValid: 0.65 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier()\n",
    "sgd.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = sgd.predict(X_test)\n",
    "sgd_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "sgd_precision=metrics.precision_score(y_test, y_pred)\n",
    "sgd_recall=metrics.recall_score(y_test, y_pred)\n",
    "print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall= ',metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "scores = cross_val_score(sgd, X, y, cv=5)\n",
    "print(\"CorssValid: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier(n_estimators=100)\n",
    "# xgb.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred = xgb.predict(X_test)\n",
    "# xgb_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "# xgb_precision=metrics.precision_score(y_test, y_pred)\n",
    "# xgb_recall=metrics.recall_score(y_test, y_pred)\n",
    "# print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "# print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "# print('Recall= ',metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ Hyperparameter Tuning --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 50, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]# Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# rf_r = RandomForestRegressor()\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_r_random = RandomizedSearchCV(estimator = rf_r, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "# rf_r_random.fit(X_train, y_train)\n",
    "# rf_r_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf=RandomForestClassifier(n_estimators=916,max_features='auto')\n",
    "# rf.fit(X_train,y_train)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred = rf.predict(X_test)\n",
    "# rf_accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "# rf_precision=metrics.precision_score(y_test, y_pred)\n",
    "# rf_recall=metrics.recall_score(y_test, y_pred)\n",
    "# print('Accuracy= ',metrics.accuracy_score(y_test, y_pred))\n",
    "# print('Precision= ',metrics.precision_score(y_test, y_pred))\n",
    "# print('Recall= ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------reuslts------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_rf=rf.predict(df_test)\n",
    "# print(op_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate submission file\n",
    "\n",
    "def submit(op):\n",
    "    df_submission=pd.DataFrame(columns=['Id','Category'])\n",
    "    ins=len(op)\n",
    "    ids=[int(i) for i in range(1,ins+1)]\n",
    "    df_submission['Id']=ids\n",
    "    cat=[]\n",
    "    for i in op:\n",
    "        if i==0:\n",
    "            cat.append('Failure')\n",
    "        elif i==1:\n",
    "            cat.append('Success')\n",
    "    df_submission['Category']=cat\n",
    "\n",
    "    \n",
    "    df_submission.to_csv(\"Group_7.csv\",index=False)\n",
    "    return df_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>Success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Category\n",
       "133  134  Success\n",
       "134  135  Success\n",
       "135  136  Success\n",
       "136  137  Success\n",
       "137  138  Success"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit(op_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
